{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 카프카에서 메시지 subscribe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실행파일을 이용한 메시지 subscribe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget http://apache.mirror.cdnetworks.com/kafka/2.3.0/kafka_2.12-2.3.0.tgz\n",
    "! tar -zxvf kafka_2.12-2.3.0.tgz   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! kafka_2.12-2.3.0/bin/kafka-console-consumer.sh \\\n",
    "--bootstrap-server localhost:9092,localhost:9093,localhost:9094 \\\n",
    "--topic exampleTopic1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting confluent_kafka\n",
      "  Downloading https://files.pythonhosted.org/packages/48/8c/01c71291da9722756304675d992eddba1c88fe3f6a4662f9c788c3f0c263/confluent_kafka-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (7.4MB)\n",
      "\u001b[K    100% |################################| 7.4MB 91kB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: confluent-kafka\n",
      "Successfully installed confluent-kafka-1.2.0\n"
     ]
    }
   ],
   "source": [
    "! pip3 install confluent_kafka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## python API를 이용한 메시지 subscribe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Consumer, KafkaException\n",
    "import sys\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create logger for consumer (logs will be emitted when poll() is called)\n",
    "logger = logging.getLogger('consumer')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "handler = logging.StreamHandler()\n",
    "handler.setFormatter(logging.Formatter('%(asctime)-15s %(levelname)-8s %(message)s'))\n",
    "logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = {'bootstrap.servers': \"localhost:9092,localhost:9093,localhost:9094\",\n",
    "        'group.id': \"ConsumerGroup1\",\n",
    "        'auto.offset.reset': 'earliest'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer = Consumer(conf, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_assignment(consumer, partitions):\n",
    "        print('Assignment:', partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer.subscribe([\"exampleTopic1\",\"exampleTopic2\"], on_assign=print_assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assignment: [TopicPartition{topic=exampleTopic1,partition=0,offset=-1001,error=None}, TopicPartition{topic=exampleTopic2,partition=0,offset=-1001,error=None}]\n",
      "<cimpl.Message object at 0x7f3f4e555660>\n",
      "b'this is kafka'\n",
      "<cimpl.Message object at 0x7f3f4e555480>\n",
      "b'Publish and subscribe to streams of records, similar to a message queue or enterprise messaging system.'\n",
      "<cimpl.Message object at 0x7f3f4e555660>\n",
      "b'Store streams of records in a fault-tolerant durable way.'\n",
      "<cimpl.Message object at 0x7f3f4e555480>\n",
      "b'Process streams of records as they occur.'\n",
      "<cimpl.Message object at 0x7f3f4e555660>\n",
      "b'Building real-time streaming data pipelines that reliably get data between systems or applications'\n",
      "<cimpl.Message object at 0x7f3f4e555480>\n",
      "b'Building real-time streaming applications that transform or react to the streams of data'\n",
      "<cimpl.Message object at 0x7f3f4e555660>\n",
      "b'Kafka is run as a cluster on one or more servers that can span multiple datacenters.'\n",
      "<cimpl.Message object at 0x7f3f4e555480>\n",
      "b'The Kafka cluster stores streams of records in categories called topics.'\n",
      "<cimpl.Message object at 0x7f3f4e555660>\n",
      "b'Each record consists of a key, a value, and a timestamp.'\n",
      "<cimpl.Message object at 0x7f3f4e555480>\n",
      "b'this is kafka'\n",
      "<cimpl.Message object at 0x7f3f4e555660>\n",
      "b'Publish and subscribe to streams of records, similar to a message queue or enterprise messaging system.'\n",
      "<cimpl.Message object at 0x7f3f4e555480>\n",
      "b'Store streams of records in a fault-tolerant durable way.'\n",
      "<cimpl.Message object at 0x7f3f4e555660>\n",
      "b'Process streams of records as they occur.'\n",
      "<cimpl.Message object at 0x7f3f4e555480>\n",
      "b'Building real-time streaming data pipelines that reliably get data between systems or applications'\n",
      "<cimpl.Message object at 0x7f3f4e555660>\n",
      "b'Building real-time streaming applications that transform or react to the streams of data'\n",
      "<cimpl.Message object at 0x7f3f4e555480>\n",
      "b'Kafka is run as a cluster on one or more servers that can span multiple datacenters.'\n",
      "<cimpl.Message object at 0x7f3f4e555660>\n",
      "b'The Kafka cluster stores streams of records in categories called topics.'\n",
      "<cimpl.Message object at 0x7f3f4e555480>\n",
      "b'Each record consists of a key, a value, and a timestamp.'\n",
      "<cimpl.Message object at 0x7f3f4e555660>\n",
      "b'this is kafka'\n",
      "<cimpl.Message object at 0x7f3f4e555480>\n",
      "b'Publish and subscribe to streams of records, similar to a message queue or enterprise messaging system.'\n",
      "<cimpl.Message object at 0x7f3f4e555660>\n",
      "b'Store streams of records in a fault-tolerant durable way.'\n",
      "<cimpl.Message object at 0x7f3f4e555480>\n",
      "b'Process streams of records as they occur.'\n",
      "<cimpl.Message object at 0x7f3f4e555660>\n",
      "b'Building real-time streaming data pipelines that reliably get data between systems or applications'\n",
      "<cimpl.Message object at 0x7f3f4e555480>\n",
      "b'Building real-time streaming applications that transform or react to the streams of data'\n",
      "<cimpl.Message object at 0x7f3f4e555660>\n",
      "b'Kafka is run as a cluster on one or more servers that can span multiple datacenters.'\n",
      "<cimpl.Message object at 0x7f3f4e555480>\n",
      "b'The Kafka cluster stores streams of records in categories called topics.'\n",
      "<cimpl.Message object at 0x7f3f4e555660>\n",
      "b'Each record consists of a key, a value, and a timestamp.'\n",
      "<cimpl.Message object at 0x7f3f4e555480>\n",
      "b'Building real-time streaming data pipelines that reliably get data between systems or applications'\n",
      "<cimpl.Message object at 0x7f3f4e555660>\n",
      "b'Building real-time streaming applications that transform or react to the streams of data'\n",
      "<cimpl.Message object at 0x7f3f4e555480>\n",
      "b'Kafka is run as a cluster on one or more servers that can span multiple datacenters.'\n",
      "<cimpl.Message object at 0x7f3f4e555660>\n",
      "b'The Kafka cluster stores streams of records in categories called topics.'\n",
      "<cimpl.Message object at 0x7f3f4e555480>\n",
      "b'Each record consists of a key, a value, and a timestamp.'\n",
      "<cimpl.Message object at 0x7f3f4e555660>\n",
      "b'Building real-time streaming data pipelines that reliably get data between systems or applications'\n",
      "<cimpl.Message object at 0x7f3f4e555480>\n",
      "b'Building real-time streaming applications that transform or react to the streams of data'\n",
      "<cimpl.Message object at 0x7f3f4e555660>\n",
      "b'Kafka is run as a cluster on one or more servers that can span multiple datacenters.'\n",
      "<cimpl.Message object at 0x7f3f4e555480>\n",
      "b'The Kafka cluster stores streams of records in categories called topics.'\n",
      "<cimpl.Message object at 0x7f3f4e555660>\n",
      "b'Each record consists of a key, a value, and a timestamp.'\n",
      "<cimpl.Message object at 0x7f3f4e555480>\n",
      "b'Building real-time streaming data pipelines that reliably get data between systems or applications'\n",
      "<cimpl.Message object at 0x7f3f4e555660>\n",
      "b'Building real-time streaming applications that transform or react to the streams of data'\n",
      "<cimpl.Message object at 0x7f3f4e555480>\n",
      "b'Kafka is run as a cluster on one or more servers that can span multiple datacenters.'\n",
      "<cimpl.Message object at 0x7f3f4e555660>\n",
      "b'The Kafka cluster stores streams of records in categories called topics.'\n",
      "<cimpl.Message object at 0x7f3f4e555480>\n",
      "b'Each record consists of a key, a value, and a timestamp.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%% Aborted by user\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    try:\n",
    "            msg = consumer.poll(1.0)\n",
    "            \n",
    "            if msg is None:\n",
    "                continue\n",
    "            if msg.error():\n",
    "                raise KafkaException(msg.error())\n",
    "            else:\n",
    "                # Proper message\n",
    "                print(msg)\n",
    "                print(msg.value())\n",
    "    except KeyboardInterrupt:\n",
    "        sys.stderr.write('%% Aborted by user\\n')\n",
    "        consumer.close()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer.subscribe([\"ticker\"], on_assign=print_assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'value'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-ae8cbfb0f4bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconsumer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'value'"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    try:\n",
    "            msg = consumer.poll(1.0)\n",
    "            \n",
    "            if msg is None:\n",
    "                continue\n",
    "            if msg.error():\n",
    "                raise KafkaException(msg.error())\n",
    "            else:\n",
    "                # Proper message\n",
    "                print(msg)\n",
    "                print(msg.value())\n",
    "                break\n",
    "    except KeyboardInterrupt:\n",
    "        sys.stderr.write('%% Aborted by user\\n')\n",
    "        consumer.close()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문제 해결\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer1 = Consumer(conf, logger=logger)\n",
    "consumer2 = Consumer(conf, logger=logger)\n",
    "consumer3 = Consumer(conf, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer1.subscribe([\"alternatives\"], on_assign=print_assignment)\n",
    "consumer2.subscribe([\"bootstrap.log\"], on_assign=print_assignment)\n",
    "consumer3.subscribe([\"dpkg.log\"], on_assign=print_assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    try:\n",
    "            msg = consumer1.poll(1.0)\n",
    "            if msg is None:\n",
    "                continue\n",
    "            if msg.error():\n",
    "                raise KafkaException(msg.error())\n",
    "            else:\n",
    "                # Proper message\n",
    "                sys.stderr.write('%% %s [%d] at offset %d with key %s:\\n' %\n",
    "                                 (msg.topic(), msg.partition(), msg.offset(),\n",
    "                                  str(msg.key())))\n",
    "                with open(\"alternatives_copied\",\"a+\") as f:\n",
    "                    f.write(msg.value())\n",
    "            \n",
    "            msg = consumer2.poll(1.0)\n",
    "            if msg is None:\n",
    "                continue\n",
    "            if msg.error():\n",
    "                raise KafkaException(msg.error())\n",
    "            else:\n",
    "                # Proper message\n",
    "                sys.stderr.write('%% %s [%d] at offset %d with key %s:\\n' %\n",
    "                                 (msg.topic(), msg.partition(), msg.offset(),\n",
    "                                  str(msg.key())))\n",
    "                \n",
    "                with open(\"bootstrap.log\",\"a+\") as f:\n",
    "                    f.write(msg.value())\n",
    "            \n",
    "            msg = consumer3.poll(1.0)\n",
    "            if msg is None:\n",
    "                continue\n",
    "            if msg.error():\n",
    "                raise KafkaException(msg.error())\n",
    "            else:\n",
    "                # Proper message\n",
    "                sys.stderr.write('%% %s [%d] at offset %d with key %s:\\n' %\n",
    "                                 (msg.topic(), msg.partition(), msg.offset(),\n",
    "                                  str(msg.key())))\n",
    "                with open(\"dpkg.log\",\"a+\") as f:\n",
    "                    f.write(msg.value())\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "    except KeyboardInterrupt:\n",
    "        sys.stderr.write('%% Aborted by user\\n')\n",
    "        consumer.close()\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
