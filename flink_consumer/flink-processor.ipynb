{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting confluent_kafka\n",
      "  Downloading https://files.pythonhosted.org/packages/48/8c/01c71291da9722756304675d992eddba1c88fe3f6a4662f9c788c3f0c263/confluent_kafka-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (7.4MB)\n",
      "\u001b[K    100% |################################| 7.4MB 223kB/s ta 0:00:011\n",
      "\u001b[?25hInstalling collected packages: confluent-kafka\n",
      "Successfully installed confluent-kafka-1.2.0\n",
      "Collecting pika\n",
      "  Downloading https://files.pythonhosted.org/packages/a1/ae/8bedf0e9f1c0c5d046db3a7428a4227fe36ec1b8e25607f3c38ac9bf513c/pika-1.1.0-py2.py3-none-any.whl (148kB)\n",
      "\u001b[K    100% |################################| 153kB 1.7MB/s ta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pika\n",
      "Successfully installed pika-1.1.0\n"
     ]
    }
   ],
   "source": [
    "! pip3 install confluent_kafka\n",
    "! pip3 install pika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Consumer, KafkaException\n",
    "import sys\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create logger for consumer (logs will be emitted when poll() is called)\n",
    "logger = logging.getLogger('consumer')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "handler = logging.StreamHandler()\n",
    "handler.setFormatter(logging.Formatter('%(asctime)-15s %(levelname)-8s %(message)s'))\n",
    "logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = {'bootstrap.servers': \"localhost:9092,localhost:9093,localhost:9094\",\n",
    "        'group.id': \"flinkConsumer\",\n",
    "        'auto.offset.reset': 'earliest'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer = Consumer(conf, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_assignment(consumer, partitions):\n",
    "        print('Assignment:', partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_list_to_csv(data_list):\n",
    "    with open('trades.csv','w') as f:\n",
    "        f.write('\"code\", \"timestamp\",\"trade_timestamp\",\"trade_price\",\"trade_volume\",\n",
    "                \"ask_bid\",\"prev_closing_price\",\"change\",\"change_price\",\"sequential_id\"\\n')\n",
    "        for data in data_list:\n",
    "            code = data[\"code\"]\n",
    "            timestamp = data[\"timestamp\"]\n",
    "            trade_timestamp = data[\"trade_timestamp\"]\n",
    "            trade_price = data[\"trade_price\"]\n",
    "            trade_volume = data[\"trade_volume\"]\n",
    "            ask_bid = data[\"ask_bid\"]\n",
    "            prev_closing_price = data[\"prev_closing_price\"]\n",
    "            change = data[\"change\"]\n",
    "            change_price = data[\"change_price\"]\n",
    "            sequential_id = data[\"sequential_id\"]\n",
    "            f.write('\"{}\",{},{},{},{},\"{}\",{},\"{}\",{},{}\\n'.format(code,timestamp,trade_timestamp,trade_price,trade_volume,\n",
    "                                                               ask_bid,prev_closing_price,change,change_price,sequential_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer.subscribe([\"trade\"], on_assign=print_assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data_list = []\n",
    "while True:\n",
    "    try:\n",
    "            msg = consumer.poll(1.0)\n",
    "            \n",
    "            if msg is None:\n",
    "                continue\n",
    "            if msg.error():\n",
    "                raise KafkaException(msg.error())\n",
    "            else:\n",
    "                # Proper message\n",
    "                data = json.loads(msg.value())\n",
    "                data_list.append(data)\n",
    "                print(data)\n",
    "            \n",
    "            if len(data_list) == 1000:\n",
    "                break\n",
    "                \n",
    "    except KeyboardInterrupt:\n",
    "        sys.stderr.write('%% Aborted by user\\n')\n",
    "        consumer.close()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_list_to_csv(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyflink.dataset import ExecutionEnvironment\n",
    "from pyflink.table import TableConfig, DataTypes, BatchTableEnvironment\n",
    "from pyflink.table.descriptors import Schema, OldCsv, FileSystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_env = ExecutionEnvironment.get_execution_environment()\n",
    "exec_env.set_parallelism(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_config = TableConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_env = BatchTableEnvironment.create(exec_env, t_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyflink.table.descriptors.BatchTableDescriptor at 0x7f743205f908>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_env.connect(FileSystem().path('./trades.csv')) \\\n",
    "    .with_format(OldCsv() \\\n",
    "                 .line_delimiter('\\n') \\\n",
    "                 .field('code', DataTypes.STRING()) \\\n",
    "                 .field('timestamp', DataTypes.BIGINT()) \\\n",
    "                 .field('trade_timestamp', DataTypes.BIGINT()) \\\n",
    "                 .field('trade_price', DataTypes.DOUBLE()) \\\n",
    "                 .field('trade_volume', DataTypes.DOUBLE()) \\\n",
    "                 .field('ask_bid', DataTypes.STRING()) \\\n",
    "                 .field('prev_closing_price', DataTypes.DOUBLE()) \\\n",
    "                 .field('change', DataTypes.STRING()) \\\n",
    "                 .field('change_price', DataTypes.DOUBLE()) \\\n",
    "                 .field('sequential_id', DataTypes.BIGINT())) \\\n",
    "    .with_schema(Schema() \\\n",
    "                 .field('code', DataTypes.STRING()) \\\n",
    "                 .field('timestamp', DataTypes.BIGINT()) \\\n",
    "                 .field('trade_timestamp', DataTypes.BIGINT()) \\\n",
    "                 .field('trade_price', DataTypes.DOUBLE()) \\\n",
    "                 .field('trade_volume', DataTypes.DOUBLE()) \\\n",
    "                 .field('ask_bid', DataTypes.STRING()) \\\n",
    "                 .field('prev_closing_price', DataTypes.DOUBLE()) \\\n",
    "                 .field('change', DataTypes.STRING()) \\\n",
    "                 .field('change_price', DataTypes.DOUBLE()) \\\n",
    "                 .field('sequential_id', DataTypes.BIGINT())) \\\n",
    "    .register_table_source('tradeSource')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyflink.table.descriptors.BatchTableDescriptor at 0x7f743185ec50>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_env.connect(FileSystem().path('./trades_result.csv')) \\\n",
    "    .with_format(OldCsv()\n",
    "                 .field_delimiter(',')\n",
    "                 .field('code', DataTypes.STRING())\n",
    "                 .field('count', DataTypes.BIGINT())) \\\n",
    "    .with_schema(Schema()\n",
    "                 .field('code', DataTypes.STRING())\n",
    "                 .field('count', DataTypes.BIGINT())) \\\n",
    "    .register_table_sink('tradeSink')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_env.scan('tradeSource') \\\n",
    "    .group_by('code') \\\n",
    "    .select('code, count(1)') \\\n",
    "    .insert_into('tradeSink')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_env.execute(\"trade_count_job\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting cluster.\n",
      "Starting standalonesession daemon on host koock-Blade.\n",
      "Starting taskexecutor daemon on host koock-Blade.\n"
     ]
    }
   ],
   "source": [
    "! /flink/build-target/bin/start-cluster.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
